{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc18b848",
   "metadata": {},
   "source": [
    "# Risk Factors :\n",
    "\n",
    "Sob a perspectiva de evitar fazer cálculos desnecessários, aumentando o risco de erros de validação, e tratamento dos dados de mercado, foram utilizados o conjunto de dados a respeito dos Fatores fornecidos pelo *NEFIN* : https://nefin.com.br/data/risk_factors.html . O conjunto de dados é dividido em 6 arquivos separados, desde $02$ de Janeiro de 2001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c44b8ba",
   "metadata": {},
   "source": [
    "In case there is an error in the read_excel of \".xls\" files:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4be2980",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff94beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# To run models:\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from joblib import dump, load\n",
    "\n",
    "# Import Linear Regression Model from SKLearn:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# For visualizations:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Project files\n",
    "from fico.evaluation import *\n",
    "from fico.portfolio import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07a05720",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6327c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.read_csv(\"../data/risk_factors/factors.csv\", index_col=\"date\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f80b2a80",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = choose_stock(\"ITUB3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prepared = process_stock(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd837f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cdec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b282cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating two Dataframes:\n",
    "combined_df = merge_portifolio(stock_prepared, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.loc[combined_df[\"Returns\"] == 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc993e60",
   "metadata": {},
   "source": [
    "## Split Train / Test Method:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bd5bb93",
   "metadata": {},
   "source": [
    "In order to preserve the temporal order of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c34c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function to split data:\n",
    "X_train, X_test, y_train, y_test, close_test = split_data(combined_df, rate=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "590bb17d",
   "metadata": {},
   "source": [
    "## Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafa761",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_model = LinearRegression(fit_intercept=True)\n",
    "lin_reg_model = lin_reg_model.fit(X_train, y_train)\n",
    "predictions = lin_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a dataframe:\n",
    "y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df = y_test.copy()\n",
    "\n",
    "# Add \"predictions\" to dataframe:\n",
    "y_test[\"Predictions\"] = predictions\n",
    "y_test[\"Close\"] = close_test\n",
    "\n",
    "# Add \"Buy Signal\" column based on whether day's predictions were greater than the day's actual returns:\n",
    "y_test[\"Buy Signal\"] = np.where(y_test[\"Predictions\"] > y_test[\"Returns\"], 1.0, 0.0)\n",
    "\n",
    "# Drop nulls:\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85537dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and view signals dataframe using generate signals function\n",
    "signals_df = generate_signals(y_test)\n",
    "display(signals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(algo_evaluation(signals_df))\n",
    "# Generate Metrics for Function vs. Buy-and-Hold Strategy:\n",
    "display(algo_vs_underlying(signals_df))\n",
    "# Generate Evaluation table:\n",
    "trade_evaluation_df = trade_evaluation(signals_df)\n",
    "display(trade_evaluation_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8197c573",
   "metadata": {},
   "source": [
    "## ANOVA Table / Other Visualizations for 3-Factor Models:\n",
    "\n",
    "### ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de76507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run models:\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7eb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y variables:\n",
    "y = combined_df.loc[:, \"Returns\"]\n",
    "X = combined_df.drop(\"Returns\", axis=1)\n",
    "X = X.drop(\"Close\", axis=1)\n",
    "\n",
    "# Add \"Constant\" column of \"1s\" to DataFrame to act as an intercept, using StatsModels:\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split into Training/Testing data:\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "# Run Ordinary Least Squares (OLS )Model:\n",
    "model = sm.OLS(y_test, X_test)\n",
    "model_results = model.fit()\n",
    "print(model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f83762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Partial Regression Plot:\n",
    "fig = sm.graphics.plot_partregress_grid(model_results, fig=plt.figure(figsize=(12, 8)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot P&L Histrogram:\n",
    "trade_evaluation_df[\"Profit/Loss\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aedc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_evaluation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_evaluation_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Cumulative Return plot using above defined function:\n",
    "underlying_returns(signals_df).plot(figsize=(20, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "203b156c",
   "metadata": {},
   "source": [
    "# VALE3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"VALE3\"\n",
    "stock = choose_stock(ticker)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22585d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prepared = process_stock(stock)\n",
    "stock_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating two Dataframes:\n",
    "combined_df = merge_portifolio(stock_prepared, factors)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, close_test = split_data(combined_df, rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ab8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, train, and predict model:\n",
    "lin_reg_model = LinearRegression(fit_intercept=True)\n",
    "lin_reg_model = lin_reg_model.fit(X_train, y_train)\n",
    "predictions = lin_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a dataframe:\n",
    "y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40981c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df = y_test.copy()\n",
    "\n",
    "# Add \"predictions\" to dataframe:\n",
    "y_test[\"Predictions\"] = predictions\n",
    "y_test[\"Close\"] = close_test\n",
    "\n",
    "# Add \"Buy Signal\" column based on whether day's predictions were greater than the day's actual returns:\n",
    "y_test[\"Buy Signal\"] = np.where(y_test[\"Predictions\"] > y_test[\"Returns\"], 1.0, 0.0)\n",
    "\n",
    "# Drop nulls:\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a643853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signals Dataframe using generate signals function\n",
    "signals_df = generate_signals(y_test)\n",
    "# Generate Metrics table for Algorithm:\n",
    "display(algo_evaluation(signals_df))\n",
    "# Generate Metrics table for Algorithm vs. Buy-and-Hold Strategy:\n",
    "display(algo_vs_underlying(signals_df))\n",
    "# Generate Metrics table for Stock using pre-defined function:\n",
    "trade_evaluation_df = trade_evaluation(signals_df)\n",
    "display(trade_evaluation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y variables:\n",
    "y = combined_df.loc[:, \"Returns\"]\n",
    "X = combined_df.drop(\"Returns\", axis=1)\n",
    "X = X.drop(\"Close\", axis=1)\n",
    "\n",
    "# Add \"Constant\" column of \"1s\" to DataFrame to act as an intercept, using StatsModels:\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split into Training/Testing data:\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "# Run Ordinary Least Squares (OLS )Model:\n",
    "model = sm.OLS(y_test, X_test)\n",
    "model_results = model.fit()\n",
    "print(model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90affb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Partial Regression Plot:\n",
    "fig = sm.graphics.plot_partregress_grid(model_results, fig=plt.figure(figsize=(12, 8)))\n",
    "plt.show()\n",
    "# Plot Cumulative Returns:\n",
    "underlying_returns(signals_df).plot(figsize=(20, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
